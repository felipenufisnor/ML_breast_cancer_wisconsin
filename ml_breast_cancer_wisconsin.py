# -*- coding: utf-8 -*-
"""ML_breast_cancer_wisconsin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nVpIVjHeOv4kB7IkaN-pR3M3CdCSRQdO
"""

import pandas as pd
import numpy as np

resultados_exames = pd.read_csv("/content/exames.xls")
resultados_exames

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from numpy import random

# Valor de aleatoriedade associada

SEED = 123143
random.seed(SEED)

# Treino e teste

valores_exames = resultados_exames.drop(["id", "diagnostico"], axis=1)
valores_exames_v1 = valores_exames.drop(columns="exame_33")
diagnostico = resultados_exames.diagnostico

treino_x, teste_x, treino_y, teste_y = train_test_split(
    valores_exames_v1, diagnostico, test_size = 0.3)

# Decision Tree

classificador = RandomForestClassifier(n_estimators = 100)
classificador.fit(treino_x, treino_y)
print("Resultado da classificação %.2f%%" % (classificador.score(teste_x, teste_y) * 100))

from sklearn.dummy import DummyClassifier

# Valor de aleatoriedade associada

SEED = 123143
random.seed(SEED)

# Dummy Classifier

classificador_dummy = DummyClassifier(strategy="most_frequent")
classificador_dummy.fit(treino_x, treino_y)

print("Resultado da classificação Dummy %.2f%%" % (classificador_dummy.score(teste_x, teste_y) * 100))

import seaborn as sns
import matplotlib.pyplot as plt

# Reajuste do DataFrame

dados_plot = pd.concat([diagnostico, valores_exames_v1.iloc[:,0:10]], axis = 1)
dados_plot = pd.melt(dados_plot, id_vars="diagnostico", 
                 var_name="exames",
                 value_name="valores")

# Gráfico

plt.figure(figsize=(10,10))

sns.violinplot(x = "exames", y = "valores", 
               hue = "diagnostico", data = dados_plot)

plt.xticks(rotation = 90)

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

# Padronizando a escala para melhorar a visualização

padronizador = StandardScaler()
padronizador.fit(valores_exames_v1)
valores_exames_v2 = padronizador.transform(valores_exames_v1)

# Transformando um array numpy em um DataFrame

valores_exames_v2 = pd.DataFrame(data = valores_exames_v2, columns=valores_exames_v1.keys())

dados_plot = pd.concat([diagnostico, valores_exames_v2.iloc[:,0:10]], axis = 1)
dados_plot = pd.melt(dados_plot, id_vars="diagnostico", 
                 var_name="exames",
                 value_name="valores")

plt.figure(figsize=(10,10))

sns.violinplot(x = "exames", y = "valores", 
               hue = "diagnostico", data = dados_plot, split = True)

plt.xticks(rotation = 90)

# Exame_4 é uma constante, logo pode ser excluída do dataset.

valores_exames_v2.exame_4

# Criando uma função para gerar os demais gráficos

def grafico_violino(valores, inicio, fim):

    dados_plot = pd.concat([diagnostico, valores.iloc[:,inicio:fim]], axis = 1)
    dados_plot = pd.melt(dados_plot, id_vars="diagnostico", 
                         var_name="exames",
                         value_name="valores")

    plt.figure(figsize=(10,10))

    sns.violinplot(x = "exames", y = "valores", hue = "diagnostico", 
                    data = dados_plot, split = True)

    plt.xticks(rotation = 90)

grafico_violino(valores_exames_v2, 10, 21)

grafico_violino(valores_exames_v2, 21, 32)

# Retirando da base de dados os 'exames' com valores nulos|constantes

valores_exames_v3 = valores_exames_v2.drop(['exame_4', 'exame_29'], axis=1)
valores_exames_v3

# Criando uma função para gerar a classificação

def classificar(valores):
    SEED = 1234
    random.seed(SEED)

# Treino e teste

    treino_x, teste_x, treino_y, teste_y = train_test_split(
        valores, diagnostico, test_size = 0.3)

# Decision Tree

    classificador = RandomForestClassifier(n_estimators = 100)
    classificador.fit(treino_x, treino_y)
    print("Resultado da classificação %.2f%%" % (classificador.score(teste_x, teste_y) * 100))

classificar(valores_exames_v3)

# Matriz de correlação e mapa de calor

matriz_correlacao = valores_exames_v3.corr()
plt.figure(figsize = (17, 15))
sns.heatmap(matriz_correlacao, annot = True, fmt = ".1f")

matriz_correlacao_v1 =  matriz_correlacao[matriz_correlacao>0.99]
matriz_correlacao_v1

matriz_correlacao_v2 = matriz_correlacao_v1.sum()
variaveis_correlacionadas = matriz_correlacao_v2[matriz_correlacao_v2>1]
variaveis_correlacionadas

valores_exames_v4 = valores_exames_v3.drop(columns=variaveis_correlacionadas.keys())
valores_exames_v4

classificar(valores_exames_v4)

valores_exames_v5 = valores_exames_v3.drop(columns=["exame_3", "exame_24"])
classificar(valores_exames_v5)

# SelectKBest -> Seleciona as melhores features, baseado naquelas com os scores mais altos.

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2

selecionar_kbest = SelectKBest(chi2, k = 5)

SEED = 1234
random.seed(SEED)

# Ajustando os valores para não termos números negativos

valores_exames_v6 = valores_exames_v1.drop(columns=["exame_4", "exame_29", "exame_3", "exame_24"])

# Adequando o modelo

treino_x, teste_x, treino_y, teste_y = train_test_split(valores_exames_v6, diagnostico, test_size = 0.3)
selecionar_kbest.fit(treino_x, treino_y)

treino_kbest = selecionar_kbest.transform(treino_x)
teste_kbest = selecionar_kbest.transform(teste_x)

teste_kbest.shape

# Utilizando o SelectKBest com Random Forest

classificador = RandomForestClassifier(n_estimators=100, random_state=1234)
classificador.fit(treino_kbest, treino_y)
print("Resultado da classificação %.2f%%" %(classificador.score(teste_kbest, teste_y) * 100))

# Análise a partir da Matriz de Confusão -> retorna uma matriz na qual os elementos 'i' são os valores reais e os elementos 'j' são os valores de predição.

from sklearn.metrics import confusion_matrix

matriz_confusao = confusion_matrix(teste_y, classificador.predict(teste_kbest))
matriz_confusao

# Gráfico da Matriz de Confusão

plt.figure(figsize = (10, 8))
sns.set(font_scale = 2)
sns.heatmap(matriz_confusao, annot = True, fmt = "d").set(xlabel = "Predição", ylabel = "Real")

# Utilizando o  RFE - Recursive Feature Elimination, algo como "Eliminação de Feature por Recursão".
# Por meio da acurácia, o RFE calcula qual das features é mais importante pra ele, descartando as de menor acurácia.

from sklearn.feature_selection import RFE

SEED = 1234
random.seed(SEED)

treino_x, teste_x, treino_y, teste_y = train_test_split(valores_exames_v6,
                                                       diagnostico,
                                                       test_size = 0.3)

# Decision Tree

classificador = RandomForestClassifier(n_estimators=100, random_state = 1234)
classificador.fit(treino_x, treino_y)

# RFE Model

selecionador_rfe = RFE(estimator = classificador, n_features_to_select = 5, step = 1)
selecionador_rfe.fit(treino_x, treino_y)
treino_rfe = selecionador_rfe.transform(treino_x)
teste_rfe = selecionador_rfe.transform(teste_x)
classificador.fit(treino_rfe, treino_y)

# Confusion Matrix

matriz_confusao = confusion_matrix(teste_y, classificador.predict(teste_rfe))
plt.figure(figsize = (10, 8))
sns.set(font_scale = 2)
sns.heatmap(matriz_confusao, annot = True, fmt = "d").set(xlabel = "Predição", ylabel = "Real")

print("Resultado da classificação %.2f%%" % (classificador.score(teste_rfe, teste_y)* 100))

# RFE Cross Validation (RFECV)
# Divide o nosso banco de dados em blocos e aplica o algoritmo RFE, em cada um desses blocos, gerando diferentes resultados.
# Dessa forma, O RFECV não só nos informa quantas features precisamos ter para gerar o melhor resultado possível, como também que features são essas.

from sklearn.feature_selection import RFECV

SEED = 1234
random.seed(SEED)

treino_x, teste_x, treino_y, teste_y = train_test_split(valores_exames_v6,
                                                       diagnostico,
                                                       test_size = 0.3)

classificador = RandomForestClassifier(n_estimators=100, random_state = 1234)
classificador.fit(treino_x, treino_y)

# RFE Cross Validation

selecionador_rfecv = RFECV(estimator = classificador, cv = 5, scoring = "accuracy", step = 1)
selecionador_rfecv.fit(treino_x, treino_y)
treino_rfecv = selecionador_rfecv.transform(treino_x)
teste_rfecv = selecionador_rfecv.transform(teste_x)
classificador.fit(treino_rfecv, treino_y)

matriz_confusao = confusion_matrix(teste_y, classificador.predict(teste_rfecv))
plt.figure(figsize = (10, 8))
sns.set(font_scale = 2)
sns.heatmap(matriz_confusao, annot = True, fmt = "d").set(xlabel = "Predição", ylabel = "Real")

print("Resultado da classificação %.2f%%" % (classificador.score(teste_rfecv, teste_y)* 100))

selecionador_rfecv.n_features_

selecionador_rfecv.support_

# Comparação dos valores com o conjunto de treino, obtendo como retorno todas as features selecionadas.

treino_x.columns[selecionador_rfecv.support_]

selecionador_rfecv.cv_results_

import matplotlib.pyplot as plt

plt.figure(figsize=(14, 8))
plt.xlabel("Número de exames")
plt.ylabel("Acurácia")

plt.plot(range(1, len(selecionador_rfecv.cv_results_) + 1), selecionador_rfecv.cv_results_)
plt.show

resultados_exames

# Plotando um gráfico a partir de 2 dimensões utilizando o RFE.

from sklearn.feature_selection import RFE

SEED = 1234
random.seed(SEED)

treino_x, teste_x, treino_y, teste_y = train_test_split(valores_exames_v6,
                                                       diagnostico,
                                                       test_size = 0.3)

classificador = RandomForestClassifier(n_estimators=100, random_state = 1234)
classificador.fit(treino_x, treino_y)


selecionador_rfe = RFE(estimator = classificador, n_features_to_select = 2, step = 1)
selecionador_rfe.fit(treino_x, treino_y)
treino_rfe = selecionador_rfe.transform(treino_x)
teste_rfe = selecionador_rfe.transform(teste_x)
classificador.fit(treino_rfe, treino_y)

matriz_confusao = confusion_matrix(teste_y, classificador.predict(teste_rfe))
plt.figure(figsize = (10, 8))
sns.set(font_scale = 2)
sns.heatmap(matriz_confusao, annot = True, fmt = "d").set(xlabel = "Predição", ylabel = "Real")

print("Resultado da classificação %.2f%%" % (classificador.score(teste_rfe, teste_y)* 100))

# Toda base de dados e apenas duas dimensões

valores_exames_v7 = selecionador_rfe.transform(valores_exames_v6)
valores_exames_v7.shape

# Grafico Scatterplot

import seaborn as sns 

plt.figure(figsize=(14, 8))
sns.scatterplot(x = valores_exames_v7[:,0], y = valores_exames_v7[:,1], hue = diagnostico)

# Principal component analysis (PCA).
# PCA opera uma transformação matemática sobre os dados, na qual as primeiras dimensões serão as variáveis que manterão o maior volume possível de informação.

from sklearn.decomposition import PCA

pca = PCA(n_components = 2)
valores_exames_v8 = pca.fit_transform(valores_exames_v6)

plt.figure(figsize=(14, 8))
sns.scatterplot(x = valores_exames_v8[:,0], y = valores_exames_v8[:,1], hue = diagnostico)

# PCA utilizando os valores padronizados. Ficou um pouco melhor, podendo traçar uma reta.

from sklearn.decomposition import PCA

pca = PCA(n_components = 2)
valores_exames_v8 = pca.fit_transform(valores_exames_v5)

plt.figure(figsize=(14, 8))
sns.scatterplot(x = valores_exames_v8[:,0], y = valores_exames_v8[:,1], hue = diagnostico)

#  T-distributed Stochastic Neighbor Embedding (t-SNE). Tenta manter as distâncias entre os pontos.
# O t-SNE tenta manter a proporção dessas distâncias na redução para dimensões menores, permitindo que tenhamos uma noção de quão distante um ponto está do outro.

from sklearn.manifold import TSNE

tsne = TSNE(n_components = 2)
valores_exames_v9 = tsne.fit_transform(valores_exames_v5)

plt.figure(figsize=(14, 8))
sns.scatterplot(x = valores_exames_v9[:,0], y = valores_exames_v9[:,1], hue = diagnostico)

